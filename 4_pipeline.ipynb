{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    \"\"\"Set up the Selenium WebDriver.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def scrape_google_news(driver):\n",
    "    \"\"\"Scrape Google News for Infosys-related articles.\"\"\"\n",
    "    driver.get(\"https://news.google.com/search?q=infosys%20when%3A1d&hl=en-IN&gl=IN&ceid=IN%3Aen\")\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        articles = driver.find_elements(By.CLASS_NAME, \"JtKRv\")\n",
    "        articles_text = [article.text for article in articles]\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", str(e))\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return articles_text\n",
    "\n",
    "\n",
    "def analyze_sentiment(articles_text):\n",
    "    \"\"\"Perform sentiment analysis on the articles.\"\"\"\n",
    "    MODEL_NAME = \"ProsusAI/finbert\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "    results = sentiment_analyzer(articles_text)\n",
    "    labels = [result[\"label\"] for result in results]\n",
    "    scores = [result[\"score\"] for result in results]\n",
    "    return labels, scores\n",
    "\n",
    "\n",
    "def calculate_sentiment_mode(labels, scores):\n",
    "    \"\"\"Calculate the mode of the sentiment and its mean score.\"\"\"\n",
    "    labels_series = pd.Series(labels)\n",
    "    sentiment_mode = labels_series.mode()[0]\n",
    "    df = pd.DataFrame({'Sentiment': labels, 'Sentiment Score': scores})\n",
    "    sentiment_mode_data = df[df['Sentiment'] == sentiment_mode]\n",
    "    mean_sentiment_score = sentiment_mode_data['Sentiment Score'].mean()\n",
    "    return sentiment_mode, mean_sentiment_score\n",
    "\n",
    "\n",
    "def scrape_nse_data(driver):\n",
    "    \"\"\"Scrape NSE website for stock data.\"\"\"\n",
    "    driver.get(\"https://www.nseindia.com/get-quotes/equity?symbol=INFY\")\n",
    "    time.sleep(5)\n",
    "    data = {}\n",
    "    try:\n",
    "        ltp_element = driver.find_element(By.ID, \"quoteLtp\")\n",
    "        data[\"Last Traded Price (LTP)\"] = ltp_element.text\n",
    "        table_xpath = '//table[@id=\"priceInfoTable\"]/tbody/tr/td'\n",
    "        table_cells = driver.find_elements(By.XPATH, table_xpath)\n",
    "        table_headers = [\"Prev. Close\", \"Open\", \"High\", \"Low\", \"Close\", \"Indicative Close\", \"VWAP\", \"Adjusted Price\"]\n",
    "        table_values = [cell.text for cell in table_cells]\n",
    "        for header, value in zip(table_headers, table_values):\n",
    "            data[header] = value\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", str(e))\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return data\n",
    "\n",
    "def preprocess_features(data, sentiment_mode, mean_sentiment_score):\n",
    "    \"\"\"Preprocess features for prediction.\"\"\"\n",
    "    sentiment_positive = sentiment_mode == 'positive'\n",
    "    sentiment_negative = sentiment_mode == 'negative'\n",
    "    sentiment_neutral = sentiment_mode == 'neutral'\n",
    "\n",
    "    features = pd.DataFrame([{\n",
    "        \"OPEN\": data['Open'],\n",
    "        \"HIGH\": data['High'],\n",
    "        \"LOW\": data['Low'],\n",
    "        \"PREV. CLOSE\": data['Prev. Close'],\n",
    "        \"ltp\": data['Last Traded Price (LTP)'],\n",
    "        \"vwap\": data['VWAP'],\n",
    "        \"Sentiment Score\": mean_sentiment_score,\n",
    "        \"Sentiment_negative\": sentiment_negative,\n",
    "        \"Sentiment_neutral\": sentiment_neutral,\n",
    "        \"Sentiment_positive\": sentiment_positive\n",
    "    }])\n",
    "\n",
    "    columns_to_convert = [\"OPEN\", \"HIGH\", \"LOW\", \"PREV. CLOSE\", \"ltp\", \"vwap\"]\n",
    "    for column in columns_to_convert:\n",
    "        features[column] = features[column].astype(str)\n",
    "        features[column] = features[column].str.replace(\",\", \"\", regex=False)  # Remove commas from the strings\n",
    "        # features[column] = features[column].str.replace(r\"[^\\\\d.]\", \"\", regex=True)\n",
    "        features[column] = pd.to_numeric(features[column], errors=\"coerce\")\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the saved stock price prediction model.\"\"\"\n",
    "    with open(\"stock_price_model.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_price(model, features):\n",
    "    \"\"\"Predict the stock price using the model.\"\"\"\n",
    "    predicted_price = model.predict(features)\n",
    "    return predicted_price[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Closing Price: 1628.45\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to orchestrate the workflow.\"\"\"\n",
    "    driver = setup_driver()\n",
    "\n",
    "    # Step 1: Scrape Google News\n",
    "    articles_text = scrape_google_news(driver)\n",
    "\n",
    "    # Step 2: Perform sentiment analysis\n",
    "    labels, scores = analyze_sentiment(articles_text)\n",
    "\n",
    "    # Step 3: Calculate sentiment mode and mean score\n",
    "    sentiment_mode, mean_sentiment_score = calculate_sentiment_mode(labels, scores)\n",
    "\n",
    "    # Step 4: Scrape NSE data\n",
    "    driver = setup_driver()  # Reinitialize driver for NSE scraping\n",
    "    nse_data = scrape_nse_data(driver)\n",
    "\n",
    "    # Step 5: Preprocess features\n",
    "    features = preprocess_features(nse_data, sentiment_mode, mean_sentiment_score)\n",
    "\n",
    "    # Step 6: Load model and predict price\n",
    "    model = load_model()\n",
    "    predicted_price = predict_price(model, features)\n",
    "\n",
    "    print(f\"Predicted Closing Price: {predicted_price:.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
